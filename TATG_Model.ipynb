{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4",
      "mount_file_id": "168XcWTmANIMBcV1xpYhGdLbOSsUadtSt",
      "authorship_tag": "ABX9TyOpvnmQn8MNs0W6/WUdWWo/",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/moosemorse/AI_Text_Detector/blob/main/TATG_Model.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Setup"
      ],
      "metadata": {
        "id": "qzPe8PSsgN-I"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#gets rid of installation dialogue\n",
        "%%capture\n",
        "!pip install transformers\n",
        "!pip install pytorch\n",
        "!pip install datasets"
      ],
      "metadata": {
        "id": "NuwK-to1gZe3"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "import matplotlib.pyplot as plt\n",
        "from google.colab import files, drive\n",
        "from datasets import load_dataset\n",
        "import pandas as pd\n",
        "import seaborn as sns\n",
        "import torch\n",
        "from torch.utils.data import Dataset, DataLoader\n",
        "from transformers import RobertaTokenizer\n",
        "import numpy as np\n",
        "import copy"
      ],
      "metadata": {
        "id": "sNuIz1VTq4T6"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#mount drive, gain access to file in google drive\n",
        "drive.mount('/content/drive', force_remount=False)\n",
        "\n",
        "#obtain csv file and store in var 'df' as dataframe\n",
        "train_path = \"drive/MyDrive/GPT-wiki-intro.csv\"\n",
        "df = pd.read_csv(train_path)"
      ],
      "metadata": {
        "id": "yjN-pLsTBIMW",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "85f89757-1beb-4957-8327-464ecc2a6794"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Inspect data"
      ],
      "metadata": {
        "id": "nNPDZfID3nqu"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#data to describe csv file\n",
        "print(df.describe())"
      ],
      "metadata": {
        "id": "doidpjeS3rBZ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df.head()"
      ],
      "metadata": {
        "id": "bTX_haHOM0HP"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(df.iloc[:].loc[:, ['wiki_intro', 'generated_intro']])\n",
        "#iloc dictates the rows indexed\n",
        "#loc dictates the columns extracted"
      ],
      "metadata": {
        "id": "TJamtDrQP6NK"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#visualisation to compare data for human-written text and ai-written text\n",
        "#testing seaborn and these could be helpful for evaluation afterwards\n",
        "sns.countplot(x = 'wiki_intro_len', data = df)\n",
        "plt.show()\n",
        "\n",
        "sns.countplot(x = 'generated_intro_len', data = df)\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "_cUllMAyH0bv"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df.max()"
      ],
      "metadata": {
        "id": "zxkRYvFai1nc"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Dataset"
      ],
      "metadata": {
        "id": "tQFOz96I3rPP"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#dataset class inherits dataset module imported from torch\n",
        "class ChatGPT_Dataset(Dataset):\n",
        "\n",
        "  def __init__(self, data_path, tokenizer, max_token_len = 512):\n",
        "    self.data_path = data_path\n",
        "    self.tokenizer = tokenizer\n",
        "    self.max_token_len = max_token_len\n",
        "    self._prepare_data()\n",
        "\n",
        "  #clean dataframe to create dataset with text needed and labels\n",
        "  #1 represents human written, 0 represents generated\n",
        "  def _prepare_data(self):\n",
        "    data = pd.read_csv(self.data_path)\n",
        "    generated = pd.DataFrame({'text': data['generated_intro'], 'label': 0})\n",
        "    wiki = pd.DataFrame({'text': data['wiki_intro'], 'label': 1})\n",
        "    self.data = pd.concat([generated, wiki])\n",
        "    self.data.label = str(self.data.label)\n",
        "\n",
        "  def __len__(self):\n",
        "    return (len(self.data))\n",
        "\n",
        "  def __getitem__(self, index):\n",
        "    item = self.data.iloc[index]\n",
        "    text = str(item.text)\n",
        "    label = torch.FloatTensor(item['label'])\n",
        "    tokens = self.tokenizer.encode_plus(item,\n",
        "                                        add_special_tokens = True,\n",
        "                                        return_tensors ='pt',\n",
        "                                        truncation = True,\n",
        "                                        max_length = self.max_token_len,\n",
        "                                        padding = 'max_length',\n",
        "                                        return_attention_mask = True)\n",
        "\n",
        "    return {'input_ids': tokens.input_ids.flatten(), 'attention_mask': tokens.attention_mask.flatten(),\n",
        "            'labels': label }"
      ],
      "metadata": {
        "id": "Gy_IfEz93vJB"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model_name = 'roberta-base'\n",
        "tokenizer = RobertaTokenizer.from_pretrained(model_name) #use pretrained tokenizer used from Roberta\n",
        "ChatGPT_ds = ChatGPT_Dataset(train_path, tokenizer) #instance of dataset\n",
        "ChatGPT_ds.__getitem__(0)"
      ],
      "metadata": {
        "id": "LEteGPV5LyUz",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 331
        },
        "outputId": "4e3ca17c-4389-497b-db7d-7e114ca4fe30"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "error",
          "ename": "TypeError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-22-5b49eeb85950>\u001b[0m in \u001b[0;36m<cell line: 4>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0mtokenizer\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mRobertaTokenizer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfrom_pretrained\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel_name\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;31m#use pretrained tokenizer used from Roberta\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0mChatGPT_ds\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mChatGPT_Dataset\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrain_path\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtokenizer\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;31m#instance of dataset\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 4\u001b[0;31m \u001b[0mChatGPT_ds\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__getitem__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m<ipython-input-21-0e3028eb43f0>\u001b[0m in \u001b[0;36m__getitem__\u001b[0;34m(self, index)\u001b[0m\n\u001b[1;32m     21\u001b[0m     \u001b[0mitem\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0miloc\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mindex\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     22\u001b[0m     \u001b[0mtext\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mstr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mitem\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtext\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 23\u001b[0;31m     \u001b[0mlabel\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mFloatTensor\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mitem\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'label'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     24\u001b[0m     tokens = self.tokenizer.encode_plus(item,\n\u001b[1;32m     25\u001b[0m                                         \u001b[0madd_special_tokens\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mTypeError\u001b[0m: new(): invalid data type 'str'"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Creating the model"
      ],
      "metadata": {
        "id": "_JqG4Q0U3vBb"
      }
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "4TAjYsM93zuw"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Evaluating the model"
      ],
      "metadata": {
        "id": "odst6nCW3zMK"
      }
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "O0Fh-Knz33Fr"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}